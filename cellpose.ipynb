{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b1fe089",
   "metadata": {},
   "source": [
    "\n",
    "# Cell Segmentation with Cellpose\n",
    "\n",
    "This notebook shows **how to run Cellpose from the command line inside a notebook** to train, infer, and (optionally) visualize results.  \n",
    "It assumes your dataset is organized under `data/` as described below.\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "```bash\n",
    "# 1) install (run once in your env)\n",
    "pip install \"cellpose[gpu]\"\n",
    "\n",
    "# 2) train with a test split for built-in evaluation\n",
    "python -m cellpose --train   --dir data/train   --test_dir data/test   --pretrained_model cyto3   --chan 0 --chan2 0   --learning_rate 0.2   --n_epochs 500   --batch_size 8   --use_gpu   --model_name my_cell_model\n",
    "\n",
    "# 3) run inference and save predicted masks as .tif\n",
    "python -m cellpose --dir data/test/images   --pretrained_model my_cell_model   --chan 0 --chan2 0   --diameter 0   --save_tif   --use_gpu\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c91a0",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Installation\n",
    "Install Cellpose (GPU build). If you're on CPU only, drop the `[gpu]` extra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e49a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install Cellpose \n",
    "# !pip install \"cellpose[gpu]\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a35ac2",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Dataset Layout\n",
    "\n",
    "Cellpose expects the following structure:\n",
    "\n",
    "```\n",
    "data/\n",
    "├─ train/\n",
    "│  ├─ images/\n",
    "│  └─ masks/\n",
    "└─ test/\n",
    "   ├─ images/\n",
    "   └─ masks/\n",
    "```\n",
    "\n",
    "- `images/` contains microscopy images (`.tif` or `.tiff`).\n",
    "- `masks/` contains corresponding masks (binary or instance-labeled).\n",
    "- **Filenames must match** between `images/` and `masks/` (e.g., `A01.tif` in both).\n",
    "- **Channel mapping note:** this project uses grayscale inputs → `--chan 0 --chan2 0`. If you have multi-channel (e.g., nuclei/cytoplasm), set them accordingly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ae38e",
   "metadata": {},
   "source": [
    "\n",
    "### Preprocessing (explained, not included)\n",
    "The dataset here was prepared from a larger internal collection using a **CSV-driven copier** that:\n",
    "- Reads `train_split.csv` and `test_split.csv` with columns `Image` and `Mask`,\n",
    "- Copies files into the layout above,\n",
    "- If a file is missing, retries an alternate extension (`.tif` ⇄ `.tiff`),\n",
    "- Logs copied/missing counts.\n",
    "\n",
    "We **omit** that script to keep this repo lean; any equivalent data mover is fine so long as the layout above is respected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d51754",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Training (with built‑in evaluation)\n",
    "\n",
    "Passing `--test_dir` makes Cellpose evaluate on that split after each epoch (object‑level metrics).  \n",
    "This cell calls the **CLI** directly from the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f416834",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train with built-in evaluation\n",
    "# !python -m cellpose --train \\\n",
    "#   --dir data/train \\\n",
    "#   --test_dir data/test \\\n",
    "#   --pretrained_model cyto3 \\\n",
    "#   --chan 0 --chan2 0 \\\n",
    "#   --learning_rate 0.2 \\\n",
    "#   --n_epochs 500 \\\n",
    "#   --batch_size 8 \\\n",
    "#   --use_gpu \\\n",
    "#   --model_name my_cell_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a259822",
   "metadata": {},
   "source": [
    "\n",
    "### What metrics does Cellpose print?\n",
    "During training with `--test_dir`, Cellpose prints validation performance each epoch. This is **instance‑level** matching (objects are matched by IoU thresholds) and typically summarized with **precision/recall/F‑scores**. It complements pixel‑level scores and is better at reflecting splits/merges of individual cells.\n",
    "\n",
    "> Tip: If you run this notebook on Linux/macOS, you can capture logs with `| tee results/logs/train_log.txt`. On Windows, use PowerShell redirection instead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7a1d60",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Inference (segment new images)\n",
    "\n",
    "Apply your trained model to a folder of images and save predicted masks as `.tif`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inference (uncomment to run)\n",
    "# !python -m cellpose --dir data/test/images \\\n",
    "#   --pretrained_model my_cell_model \\\n",
    "#   --chan 0 --chan2 0 \\\n",
    "#   --diameter 0 \\\n",
    "#   --save_tif \\\n",
    "#   --use_gpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a38fb54",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Visual Sanity Check — Overlay prediction on the image\n",
    "\n",
    "This cell displays an image and its predicted mask as an overlay so you can quickly verify segmentation quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99347700",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional visualization (change filenames to an example that exists in your data)\n",
    "# from skimage.io import imread\n",
    "# from skimage.color import label2rgb\n",
    "# import matplotlib.pyplot as plt\n",
    "# from pathlib import Path\n",
    "#\n",
    "# img_path = Path('data/test/images') / 'example.tif'     # <-- change me\n",
    "# pr_path  = Path('results/predictions') / 'example.tif'  # <-- change me\n",
    "#\n",
    "# img = imread(img_path)\n",
    "# mask = imread(pr_path)\n",
    "# overlay = label2rgb(mask, image=img, alpha=0.3, bg_label=0)\n",
    "#\n",
    "# plt.figure(figsize=(12,5))\n",
    "# plt.subplot(1,2,1); plt.title('Image');   plt.axis('off'); plt.imshow(img, cmap='gray')\n",
    "# plt.subplot(1,2,2); plt.title('Overlay'); plt.axis('off'); plt.imshow(overlay)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6702aa",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Troubleshooting\n",
    "\n",
    "- **Masks empty or under‑segmented?** Try setting a fixed size (`--diameter 20` as a starting guess) or tune thresholds (`--cellprob_threshold`, `--flow_threshold`).  \n",
    "- **GPU not used?** Ensure CUDA is installed and `--use_gpu` is set. If needed, try `pip install cupy-cudaXXX` (matching your CUDA) or use CPU by omitting `--use_gpu`.  \n",
    "- **Channel confusion?** Double‑check `--chan`/`--chan2`. For grayscale, `0/0` is fine. For RGB, `--chan 1` (green), `--chan2 2` (blue), etc., depending on your biology.  \n",
    "- **File pairing issues?** Make sure filenames in `images/` and `masks/` are identical (including extension).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca801b3",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Using the Cellpose GUI (Optional)\n",
    "\n",
    "Cellpose also provides a **graphical user interface (GUI)** which can be very useful for:\n",
    "\n",
    "- Manually checking segmentation quality  \n",
    "- Editing masks (add/remove cells)  \n",
    "- Running inference interactively on images  \n",
    "- Evaluating how well your trained model generalizes\n",
    "\n",
    "To start the GUI after installing Cellpose, run in a terminal:\n",
    "\n",
    "```bash\n",
    "cellpose\n",
    "```\n",
    "\n",
    "or, from Python:\n",
    "\n",
    "```bash\n",
    "python -m cellpose\n",
    "```\n",
    "\n",
    "This opens the GUI window where you can drag and drop images, apply your model, and visually inspect the results.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
